{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txg4dtCfez9F"
      },
      "outputs": [],
      "source": [
        "# WEEK 2\n",
        "\n",
        "df_opt.createOrReplaceTempView(\"telecom_logs\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        customerID,\n",
        "        tenure,\n",
        "        MonthlyCharges,\n",
        "        TotalCharges,\n",
        "        -- 90-day rolling averages (window func magic!)\n",
        "        avg(MonthlyCharges) OVER (\n",
        "            PARTITION BY customerID\n",
        "            ORDER BY tenure\n",
        "            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW\n",
        "        ) as avg_monthly_90d,\n",
        "        sum(tenure) OVER (PARTITION BY customerID) as total_tenure,\n",
        "        max(TotalCharges) OVER (PARTITION BY customerID) as max_bill,\n",
        "        count(*) OVER (PARTITION BY customerID) as session_count,\n",
        "        Churn\n",
        "    FROM telecom_logs\n",
        "\"\"\").createOrReplaceTempView(\"features_raw\")\n",
        "\n",
        "df_features = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        customerID,\n",
        "        avg_monthly_90d,\n",
        "        total_tenure,\n",
        "        max_bill,\n",
        "        session_count,\n",
        "        Churn,\n",
        "        -- High-value flag (production business logic)\n",
        "        CASE WHEN TotalCharges > 1000 THEN 1 ELSE 0 END as high_value\n",
        "    FROM features_raw\n",
        "    GROUP BY customerID, avg_monthly_90d, total_tenure, max_bill, session_count, Churn, TotalCharges\n",
        "\"\"\").cache()\n",
        "\n",
        "print(\" SQL Features Created:\")\n",
        "df_features.show(10)\n",
        "df_features.printSchema()\n",
        "print(f\"Features shape: {df_features.count():,} rows\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WEEK 2\n",
        "# SPEC: \"Analyze Spark Execution Plan (DAG)\"\n",
        "\n",
        "print(\"PRODUCTION: Spark DAG Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Physical plan (ASCII graph!)\n",
        "plan = df_features.explain(True)  # Extended = full graph\n",
        "print(plan)\n",
        "\n",
        "print(\"\\n EXECUTION STATS (PRODUCTION):\")\n",
        "print(f\"• Partitions: {df_features.rdd.getNumPartitions()}\")\n",
        "print(f\"• Feature columns: {len(df_features.columns)}\")\n",
        "print(f\"• Rows: {df_features.count():,}\")\n",
        "print(f\"• Churn rate: {df_features.select(mean('Churn')).collect()[0][0]:.1%}\")\n",
        "\n",
        "# Tuning\n",
        "df_tuned = df_features.repartition(20).persist()\n",
        "print(f\"\\n Tuned: {df_tuned.rdd.getNumPartitions()} partitions\")\n",
        "\n",
        "print(\"\\n DAG analyzed and the features.\")\n",
        "df_tuned.show(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "XRSOn5StfSS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WEEK 2\n",
        "available_numeric = ['avg_monthly_90d', 'total_tenure', 'max_bill', 'session_count', 'high_value']\n",
        "if 'tenure' in df_tuned.columns: available_numeric = ['tenure'] + available_numeric\n",
        "if 'MonthlyCharges' in df_tuned.columns: available_numeric = ['MonthlyCharges'] + available_numeric\n",
        "if 'TotalCharges' in df_tuned.columns: available_numeric = ['TotalCharges'] + available_numeric\n",
        "\n",
        "print(\"Safe features:\", available_numeric)\n",
        "\n",
        "df_ml_ready = df_tuned.select(\"Churn\", *available_numeric).na.fill(0).cache()\n",
        "df_ml_ready.show(5)\n",
        "print(f\"Shape: {df_ml_ready.count()} rows x {len(available_numeric)+1} cols\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pZcCQt7BfVBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDbOY7VLfXSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}