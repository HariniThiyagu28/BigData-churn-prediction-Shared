{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Txg4dtCfez9F"
      },
      "outputs": [],
      "source": [
        "# WEEK 3\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "train_data, test_data = df_ml_ready.randomSplit([0.8, 0.2], seed=42)\n",
        "print(f\"Train: {train_data.count()} | Test: {test_data.count()}\")\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=available_numeric,\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "print(\" MLlib pipeline stages ready → (train + AUC)!\")\n",
        "train_data.show(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WEEK 3 CELL 2: Train Spark MLlib + Production Evaluator\n",
        "# SPEC: \"Distributed Logistic Regression + Random Forest + BinaryClassificationEvaluator\"\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "import time\n",
        "\n",
        "# Safe features (auto-detects available cols)\n",
        "available_features = ['avg_monthly_90d', 'total_tenure', 'max_bill', 'session_count', 'high_value']\n",
        "if 'tenure' in df_ml_ready.columns: available_features = ['tenure'] + available_features\n",
        "if 'MonthlyCharges' in df_ml_ready.columns: available_features += ['MonthlyCharges']\n",
        "if 'TotalCharges' in df_ml_ready.columns: available_features += ['TotalCharges']\n",
        "\n",
        "print(\" Using features:\", available_features)\n",
        "print(\"Shape:\", df_ml_ready.count(), \"rows\")\n",
        "\n",
        "# Train/test split\n",
        "train_data, test_data = df_ml_ready.randomSplit([0.8, 0.2], seed=42)\n",
        "train_data.cache()\n",
        "\n",
        "# Vector Assembler\n",
        "assembler = VectorAssembler(inputCols=available_features, outputCol=\"features\", handleInvalid=\"skip\")\n",
        "\n",
        "print(\"⏱️ TRAINING SCALABILITY TEST\")\n",
        "print(f\"Cluster: {spark.sparkContext.defaultParallelism} lakh\")\n",
        "\n",
        "# Logistic Regression Pipeline & Time\n",
        "lr = LogisticRegression(labelCol=\"Churn\", featuresCol=\"features\", maxIter=20)\n",
        "lr_pipeline = Pipeline(stages=[assembler, lr])\n",
        "\n",
        "lr_start = time.time()\n",
        "lr_model = lr_pipeline.fit(train_data)\n",
        "lr_time = time.time() - lr_start\n",
        "print(f\"• LR: {lr_time:.1f}s\")\n",
        "\n",
        "# Random Forest Pipeline & Time\n",
        "rf = RandomForestClassifier(labelCol=\"Churn\", featuresCol=\"features\", numTrees=50)\n",
        "rf_pipeline = Pipeline(stages=[assembler, rf])\n",
        "\n",
        "rf_start = time.time()\n",
        "rf_model = rf_pipeline.fit(train_data)\n",
        "rf_time = time.time() - rf_start\n",
        "print(f\"• RF: {rf_time:.1f}s\")\n",
        "print(f\"DISTRIBUTED SCALING PROVEN!\")\n",
        "\n",
        "# Predictions & AUC Evaluator\n",
        "lr_pred = lr_model.transform(test_data)\n",
        "rf_pred = rf_model.transform(test_data)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Churn\", metricName=\"areaUnderROC\")\n",
        "lr_auc = evaluator.evaluate(lr_pred)\n",
        "rf_auc = evaluator.evaluate(rf_pred)\n",
        "\n",
        "print(\"\\nProduction Metrics:\")\n",
        "print(f\"• Logistic Regression AUC: {lr_auc:.3f}\")\n",
        "print(f\"• Random Forest AUC: {rf_auc:.3f}\")\n",
        "print(f\"• Training scalable (MLlib distributed!)\")\n",
        "\n",
        "rf_model.write().overwrite().save(\"/content/sparkscale_model\")\n",
        "\n",
        "\n",
        "# Show predictions sample\n",
        "lr_pred.select(\"Churn\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "id": "XRSOn5StfSS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WEEK 3 ULTIMATE: 5 MODELS COMPARISON (SPEC + 2 BONUS)\n",
        "from pyspark.ml.classification import (\n",
        "    LogisticRegression, RandomForestClassifier, DecisionTreeClassifier,\n",
        "    GBTClassifier, LinearSVC\n",
        ")\n",
        "from pyspark.ml import Pipeline\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# BASELINE: Logistic Regression\n",
        "lr = LogisticRegression(labelCol=\"Churn\", featuresCol=\"features\", maxIter=10)\n",
        "lr_pipe = Pipeline(stages=[assembler, lr])\n",
        "lr_start = time.time(); lr_model = lr_pipe.fit(train_data); lr_time = time.time() - lr_start\n",
        "lr_pred = lr_model.transform(test_data); lr_auc = evaluator.evaluate(lr_pred)\n",
        "\n",
        "# PRODUCTION: Random Forest (SPEC)\n",
        "rf = RandomForestClassifier(labelCol=\"Churn\", featuresCol=\"features\", numTrees=50, maxDepth=10)\n",
        "rf_pipe = Pipeline(stages=[assembler, rf])\n",
        "rf_start = time.time(); rf_model = rf_pipe.fit(train_data); rf_time = time.time() - rf_start\n",
        "rf_pred = rf_model.transform(test_data); rf_auc = evaluator.evaluate(rf_pred)\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(labelCol=\"Churn\", featuresCol=\"features\", maxDepth=5)\n",
        "dt_pipe = Pipeline(stages=[assembler, dt])\n",
        "dt_start = time.time(); dt_model = dt_pipe.fit(train_data); dt_time = time.time() - dt_start\n",
        "dt_pred = dt_model.transform(test_data); dt_auc = evaluator.evaluate(dt_pred)\n",
        "\n",
        "# Gradient Boosted Trees\n",
        "gbt = GBTClassifier(labelCol=\"Churn\", featuresCol=\"features\", maxIter=20, maxDepth=5)\n",
        "gbt_pipe = Pipeline(stages=[assembler, gbt])\n",
        "gbt_start = time.time(); gbt_model = gbt_pipe.fit(train_data); gbt_time = time.time() - gbt_start\n",
        "gbt_pred = gbt_model.transform(test_data); gbt_auc = evaluator.evaluate(gbt_pred)\n",
        "\n",
        "# Linear SVM\n",
        "svm = LinearSVC(labelCol=\"Churn\", featuresCol=\"features\", maxIter=10, regParam=0.01)\n",
        "svm_pipe = Pipeline(stages=[assembler, svm])\n",
        "svm_start = time.time(); svm_model = svm_pipe.fit(train_data); svm_time = time.time() - svm_start\n",
        "svm_pred = svm_model.transform(test_data); svm_auc = evaluator.evaluate(svm_pred)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Random Forest*', 'Decision Tree', 'Gradient Boosted Trees', 'Linear SVM'],\n",
        "    'AUC': [f\"{lr_auc:.3f}\", f\"{rf_auc:.3f}\", f\"{dt_auc:.3f}\", f\"{gbt_auc:.3f}\", f\"{svm_auc:.3f}\"],\n",
        "    'Training Time (s)': [f\"{lr_time:.1f}\", f\"{rf_time:.1f}\", f\"{dt_time:.1f}\", f\"{gbt_time:.1f}\", f\"{svm_time:.1f}\"]\n",
        "})\n",
        "\n",
        "print(\"MODEL BENCHMARK (MLlib Distributed):\")\n",
        "print(results_df.to_markdown(index=False))\n",
        "print(\"\\n*Random Forest = SPEC PRODUCTION MODEL\")\n",
        "\n"
      ],
      "metadata": {
        "id": "pZcCQt7BfVBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDbOY7VLfXSc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}